{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Twitter to Predict Stock Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea for this project started in a writing class that I took as a Senior at Brigham Young University. The assignment was to write a 10-page literature review regarding a subject that we were interested in. I love to watch my Robinhood account go up and down with the stock market and after learning so much about machine learning I thought there must be some way to predict the stock market. I began to research different methods of machine learning in stock prediction and surprisingly there were several articles about using natural language processing to predict stock fluctuations. One of their primary data sources was Twitter. I thought that it would be interesting to try out my new knowledge in machine learning and NLP to perform an analysis similar to the ones that I had been reading. The literature review that I wrote can be found in the https://github.com/andersonb97/RockinRobin repository if you would like to read more regarding my findings.\n",
    "\n",
    "The purpose of this document is to demonstrate my skills in machine learning and natural language processing. My research question is, \"Can tweets be used to predict individual stock price changes?\"\n",
    "\n",
    "This project contains steps and information regarding my analysis including:\n",
    "* Data Collection\n",
    "* Cleaning\n",
    "* EDA\n",
    "* Variable Creation\n",
    "* Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "#### Twitter\n",
    "\n",
    "Twitter data can be pulled using Twitter's API which is readily available to students and for other projects. API access is granted to Twitter users who have applied for developer status. A quick description of the project is required and API keys are granted upon project approval.\n",
    "\n",
    "To pull the twitter data I used a package called 'Tweepy' which has a couple of shortcomings including that you can only pull tweets from the last week. This limited the amount of data that I was able to obtain significantly because I was limited to three week's worth of data in the time span of my project. I coded my data pull to include the most recent 10,000 for each company in the S&P 500 for a given day. My pull resulted in a Pandas data frame where each row contained:\n",
    "\n",
    "* Tweet\n",
    "* Username who tweeted\n",
    "* Location from which the tweet was made\n",
    "* Tweet timestamp\n",
    "* Search words\n",
    "\n",
    "The search words used to find each tweet contained the name of the company, the ticker symbol in the US stock exchange, and the modifier \"-filter:retweets\". The modifier \"-filter:retweets\" ensured that I didn't get duplicate tweets. An example search word phrase for Tesla would be \"TSLA OR Tesla -filter:retweets\". The resulting data frame is then saved as a .csv file. \n",
    "\n",
    "Full code for my Twitter data pull is provided in the Github repository: https://github.com/andersonb97/RockinRobin in the file tweetPull.ipynb. \n",
    "\n",
    "#### Yahoo! Finance\n",
    "\n",
    "The financial data necessary for this project was scraped from Yahoo! Finance using the 'read_html()' function in the Pandas package. \n",
    "A list of S&P 500 companies with their name and ticker symbol were scraped from Wikipedia (https://en.wikipedia.org/wiki/List_of_S%26P_500_companies). \n",
    "\n",
    "Using the resulting ticker symbols I created a scrape using the following form to obtain recent stock data: \n",
    "\n",
    "'https://finance.yahoo.com/quote/' + ticker + '/history?p=' + ticker \n",
    "\n",
    "- where 'ticker' represents the ticker symbol for a company as a string.\n",
    "\n",
    "Using the resulting data I created two variables: delta and delta_bin. \"delta\" is the numeric change between opening and closing price. \"delta_bin\" is the categorical change in stock price, either \"positive\" or \"negative\".\n",
    "\n",
    "Full code for my Twitter data pull is provided in the Github repository (https://github.com/andersonb97/RockinRobin) in the file stockPull.ipynb. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.util import ngrams\n",
    "from os import listdir, getcwd\n",
    "from collections import Counter\n",
    "from os.path import isfile, join\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk import wordpunct_tokenize, word_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in stock data.\n",
    "stocks = pd.read_csv('stockData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Tweet data files.\n",
    "onlyfiles = [f for f in listdir(getcwd()) if isfile(join(getcwd(), f))]\n",
    "# Read and concatenate all twitter data files.\n",
    "tweets = pd.concat([pd.read_csv(file) for file in [i for i in onlyfiles if 'tweetData' in i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Stocks Data\n",
    "\n",
    "The stock data is fairly cleaned based of the pull that I did. During the pull I removed any rows containing strings (stock splits). However, there are some duplicates in the data so it is necessary for me to remove duplicates. In addition, I change the date into a format consistent with the date data that I collected from Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some duplicates that need to be removed in the stock data.\n",
    "stocks = stocks.drop_duplicates(['ticker', 'Date'])[['ticker', 'Date', 'delta_bin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks['date'] = [dt.datetime.strptime(i, '%b %d, %Y').strftime('%Y-%m-%d') for i in stocks.Date]\n",
    "stocks = stocks.drop('Date', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Twitter Data\n",
    "\n",
    "The first step to cleaning twitter data was to rename the columns. Then I need to take out the ticker symbol and drop unnecessary columns. After this brief cleaning the next step is the clean the text of the tweets. To do this I turn the words into lowercase, split the words, and remove stop words. The stop words that I use come from the 'english' dictionary in the NLTK package.\n",
    "\n",
    "The final step in the twitter data cleaning is to combine the text strings for each company each day. So if 20 people tweeted about Tesla on the same day, we concatenate those strings into one string and one data observation for Tesla that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "tweets.columns = ['tweet', 'user', 'location', 'date', 'retweets', 'searchwords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the ticker symbol from searchwords\n",
    "tweets['ticker'] = [i.split(' OR')[0] for i in tweets['searchwords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "tweets = tweets.drop_duplicates(['tweet', 'date', 'ticker'])[['tweet', 'date', 'ticker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the tweets to remove stopwords and symobols\n",
    "sw = stopwords.words('english')\n",
    "def clean_text(x):\n",
    "    x = x.lower()\n",
    "    words = x.split()\n",
    "    words = [w for w in words if w not in sw]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    return \" \".join(words)\n",
    "\n",
    "tweets['tweet'] = tweets['tweet'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one string from all of the tweets regarding that company on that day.\n",
    "tweets['date'] = [i.split(' ')[0] for i in tweets['date']]\n",
    "tweets_grouped = tweets.groupby(['date', 'ticker'])\n",
    "grouped_lists = tweets_grouped[\"tweet\"].agg(lambda column: \" \".join(column))\n",
    "tweets = grouped_lists.reset_index(name=\"tweet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Data Frames\n",
    "\n",
    "With both data frames clean we can combine them into one data frame. This data frame we call dataFinal and it is created using a left merge on 'date' and 'ticker' symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames together to see if tweets from the day affect closing price\n",
    "dataFinal = tweets.merge(stocks, left_on=['date', 'ticker'], right_on=[ 'date', 'ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>tweet</th>\n",
       "      <th>delta_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>AAP</td>\n",
       "      <td>highlights annual mobil twelve hours sebring p...</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>ANTM</td>\n",
       "      <td>today released legendary anthem empowerment no...</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>BLK</td>\n",
       "      <td>years ago michael jordan ridiculous line vs pt...</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>CARR</td>\n",
       "      <td>south korean korean air says buy smaller troub...</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>CE</td>\n",
       "      <td>great post awhile ago rise nazi hippies worth ...</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker                                              tweet  \\\n",
       "0  2020-11-16    AAP  highlights annual mobil twelve hours sebring p...   \n",
       "1  2020-11-16   ANTM  today released legendary anthem empowerment no...   \n",
       "2  2020-11-16    BLK  years ago michael jordan ridiculous line vs pt...   \n",
       "3  2020-11-16   CARR  south korean korean air says buy smaller troub...   \n",
       "4  2020-11-16     CE  great post awhile ago rise nazi hippies worth ...   \n",
       "\n",
       "  delta_bin  \n",
       "0      down  \n",
       "1      down  \n",
       "2      down  \n",
       "3        up  \n",
       "4        up  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFinal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "My analysis focuses on two different approaches: Semantic Models and Sentiment Models. This is something that is discussed in the literature review I attached. Because I focus on Semantic and Sentiment models I look into two different points in my exploratory data analysis. For semantic analysis EDA, I look at word counts within the tweets along with bigrams and trigrams. For sentiment analysis, I look more into the sentiment behind the tweets in general regarding the stock market. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Counts\n",
    "\n",
    "Popular words in the tweets collected include 'new', 'walmart' and 'trump'. This really doesn't give us a ton of insight into the tweets other than important names and companies included in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>new</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>548</td>\n",
       "      <td>johnson</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>662</td>\n",
       "      <td>key</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>cop</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1188</td>\n",
       "      <td>walmart</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>says</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>trump</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>anthem</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>people</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>one</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  count\n",
       "222       new    150\n",
       "548   johnson    131\n",
       "662       key    130\n",
       "230       cop    124\n",
       "1188  walmart    104\n",
       "75       says     91\n",
       "70      trump     90\n",
       "15     anthem     85\n",
       "49     people     84\n",
       "20        one     83"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_content = \" \".join(list(dataFinal['tweet'])).split()\n",
    "c = Counter(long_content)\n",
    "wc_total = pd.DataFrame(c.items(), columns=['word', 'count'])\n",
    "wc_total.sort_values(by='count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_plot = wc_total.sort_values(by='count',ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d5176d1c88>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.barplot(x='word', y='count',data=for_plot, palette='cividis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count bigrams/trigrams\n",
    "\n",
    "Bigrams and trigrams give us a little more insight into the topics that are commonly discussed in the tweets. Important names of companies and individuals are included in the bigrams while trigrams give us insight into topics discussed. In the bigrams you see names of companies like GM, Tyson, Paypal, and Home Depot. In the trigrams we see topics immerge such as singing the national anthem, army missions, and cashapps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = ngrams(long_content, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic = pd.DataFrame(c2.items(), columns=['word','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>692</td>\n",
       "      <td>(boris, johnson)</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>533</td>\n",
       "      <td>(general, motors)</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5389</td>\n",
       "      <td>(tyson, foods)</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>(national, anthem)</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9341</td>\n",
       "      <td>(black, friday)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1124</td>\n",
       "      <td>(joe, biden)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7303</td>\n",
       "      <td>(many, workers)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1382</td>\n",
       "      <td>(paypal, venmo)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2276</td>\n",
       "      <td>(home, depot)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6107</td>\n",
       "      <td>(motors, says)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7304</td>\n",
       "      <td>(workers, would)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>(black, man)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1381</td>\n",
       "      <td>(cashapp, paypal)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>(donald, trump)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6036</td>\n",
       "      <td>(hazard, pay)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    word  count\n",
       "692     (boris, johnson)     49\n",
       "533    (general, motors)     41\n",
       "5389      (tyson, foods)     31\n",
       "47    (national, anthem)     29\n",
       "9341     (black, friday)     12\n",
       "1124        (joe, biden)     12\n",
       "7303     (many, workers)     12\n",
       "1382     (paypal, venmo)     11\n",
       "2276       (home, depot)     11\n",
       "6107      (motors, says)     11\n",
       "7304    (workers, would)     11\n",
       "262         (black, man)     11\n",
       "1381   (cashapp, paypal)     10\n",
       "1060     (donald, trump)     10\n",
       "6036       (hazard, pay)     10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bic.sort_values(by='count',ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7649</td>\n",
       "      <td>(many, workers, would)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6380</td>\n",
       "      <td>(general, motors, says)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3530</td>\n",
       "      <td>(alpha, phi, alpha)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>(post, cashapp, paypal)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1411</td>\n",
       "      <td>(cashapp, paypal, venmo)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1412</td>\n",
       "      <td>(paypal, venmo, bitcoin)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>(sing, national, anthem)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2423</td>\n",
       "      <td>(omega, psi, phi)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7349</td>\n",
       "      <td>(mission, army, vet)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7650</td>\n",
       "      <td>(workers, would, get)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12894</td>\n",
       "      <td>(penguin, random, house)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14277</td>\n",
       "      <td>(near, today, worth)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14276</td>\n",
       "      <td>(nio, near, today)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14278</td>\n",
       "      <td>(today, worth, general)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14275</td>\n",
       "      <td>(startup, nio, near)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           word  count\n",
       "7649     (many, workers, would)     11\n",
       "6380    (general, motors, says)      9\n",
       "3530        (alpha, phi, alpha)      9\n",
       "1410    (post, cashapp, paypal)      9\n",
       "1411   (cashapp, paypal, venmo)      8\n",
       "1412   (paypal, venmo, bitcoin)      8\n",
       "47     (sing, national, anthem)      7\n",
       "2423          (omega, psi, phi)      7\n",
       "7349       (mission, army, vet)      7\n",
       "7650      (workers, would, get)      6\n",
       "12894  (penguin, random, house)      6\n",
       "14277      (near, today, worth)      6\n",
       "14276        (nio, near, today)      6\n",
       "14278   (today, worth, general)      6\n",
       "14275      (startup, nio, near)      6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = ngrams(long_content, 3)\n",
    "c3 = Counter(trigrams)\n",
    "pd.DataFrame(c3.items(), columns=['word','count']).sort_values(by='count', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment\n",
    "\n",
    "Sentiment analysis involves assigning sentiment to each word and tweet. The sentiment lexicon that we use is suggested by Mishev et al. (2020) in the publication \"Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers\". This article suggests the use of the Loughran McDonald Dictionary for financial data. This dataset includes 86,486 words with 2,355 negatively connotated words, and 354 positively connotated words. \n",
    "\n",
    "Based on the EDA performed on general tweet sentiment words such as 'good', 'happy', 'best', and 'win' were very commonly used to indicate positive sentiment. Words such as 'fired', 'breaking', 'accused' and 'lost' are very common negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in sentiments\n",
    "sentiments = pd.read_csv('LoughranMcDonald_MasterDictionary_2018.csv')\n",
    "sentiments['word'] = [str(i).lower() for i in sentiments['Word']]\n",
    "sentiments = sentiments.drop('Word', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments['sentiment'] = ['positive' if int(sentiments['Positive'][i]) > 0 else 'negative' if int(sentiments['Negative'][i]) > 0 else 'neutral' for i in range(len(sentiments['Positive']))]\n",
    "sentiments = sentiments[['word', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>highlights</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>annual</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>twelve</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>hours</td>\n",
       "      <td>7</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>presented</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  count sentiment\n",
       "0  highlights      3   neutral\n",
       "1      annual      5   neutral\n",
       "2      twelve      2   neutral\n",
       "3       hours      7   neutral\n",
       "4   presented      3   neutral"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = pd.merge(wc_total, sentiments, how='inner')\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     5134\n",
       "negative     348\n",
       "positive     100\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = new[new['sentiment']=='positive'].sort_values(by='count',ascending=False).head(10)\n",
    "n = new[new['sentiment']=='negative'].sort_values(by='count',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d5188e7308>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.barplot(x='word', y='count',data=p,palette='spring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d5185de788>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAE9CAYAAADwNV8FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAaRUlEQVR4nO3deZRtV10n8O+PJMwBE/MIYYjBrAgiC0PzxIEpAtJRFzIFMAKdoBJwgJaWxUJtMYLa0CiooGhQSBhUwECMoEAMQ4JMvkDyeAnQcUkYQ4YGFGxAEnf/cXalLsV7b1eSuvdWvff5rFWrzj33nHt/Z9cZvrXvOfdUay0AAMCe3WTZBQAAwGYnNAMAwIDQDAAAA0IzAAAMCM0AADAgNAMAwMCByy5gPQ477LB21FFHLbsMAAD2cRdccMHVrbVta8dvidB81FFHZceOHcsuAwCAfVxVfXJ3452eAQAAA0IzAAAMCM0AADAgNAMAwIDQDAAAA0IzAAAMCM0AADAgNAMAwIDQDAAAA0IzAAAMCM0AADBw4LILuLG+416XLLuEDffJD9992SUAADBDTzMAAAwIzQAAMCA0AwDAgNAMAAADQjMAAAwIzQAAMCA0AwDAgNAMAAADQjMAAAwIzQAAMCA0AwDAgNAMAAADQjMAAAwIzQAAMCA0AwDAgNAMAAADQjMAAAwIzQAAMCA0AwDAgNAMAAADQjMAAAwIzQAAMCA0AwDAgNAMAAADQjMAAAwIzQAAMCA0AwDAgNAMAAADQjMAAAzMLTRX1Z2r6p1V9dGquriq/nsff2hVnVNVl/bfh8yrBgAA2Ajz7Gm+Jskvt9a+O8kPJPmFqrp7kmcnObe1dkySc/tjAADYtOYWmltrl7fWPtSHv5zko0numOThSc7ok52R5BHzqgEAADbCQs5prqqjktwryQeSHN5auzyZgnWS2y2iBgAAuKHmHpqr6tZJzkzyS621f7se851SVTuqasdVV101vwIBAGBgrqG5qg7KFJhf21p7Yx99RVUd0Z8/IsmVu5u3tXZaa217a237tm3b5lkmAADs1Ty/PaOS/HmSj7bWXjTz1NlJTurDJyX5m3nVAAAAG+HAOb72fZM8MclHqurCPu5Xkzw/yeur6meSfCrJY+ZYAwAA3GhzC82ttfckqT08/eB5vS8AAGw0dwQEAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBg4MBlF8DGOfK4HcsuYcN96l3bl10CAICeZgAAGBGaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgYG6huapeUVVXVtWumXGnVtVnq+rC/vNj83p/AADYKPPsaT49yfG7Gf/i1tqx/efv5vj+AACwIeYWmltr5yX5wrxeHwAAFmUZ5zT/YlXt7KdvHLKE9wcAgOtl0aH5ZUmOTnJsksuT/N6eJqyqU6pqR1XtuOqqqxZVHwAAfIuFhubW2hWttWtba/+Z5OVJ7rOXaU9rrW1vrW3ftm3b4ooEAIA1Fhqaq+qImYePTLJrT9MCAMBmceC8Xriq/jLJcUkOq6rPJPmNJMdV1bFJWpLLkjxlXu8PAAAbZW6hubV24m5G//m83g8AAObFHQEBAGBAaAYAgAGhGQAABoRmAAAYEJoBAGBAaAYAgIG5feUcLNOdH3HeskvYcJ8+6wHLLgEA9lt6mgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYGBdobmqzl3POAAA2Bft9TbaVXXzJLdMclhVHZKk+lO3SXKHOdcGbIA7Punvl13ChvvsK3/0es9zh2ecOYdKlu9zL370sksA2C/sNTQneUqSX8oUkC/Iamj+tyR/NMe6AABg09hraG6t/UGSP6iqp7XWXrKgmgAAYFMZ9TQnSVprL6mqH0py1Ow8rbVXzakuAADYNNYVmqvq1UmOTnJhkmv76JZEaAYAYJ+3rtCcZHuSu7fW2jyLAQCAzWi939O8K8nt51kIAABsVuvtaT4sySVV9cEkX18Z2Vr7iblUBQAAm8h6Q/Op8ywCAAA2s/V+e8a7510IAABsVuv99owvZ/q2jCS5aZKDkvx7a+028yoMAAA2i/X2NB88+7iqHpHkPnOpCAAANpn1ntP8TVprZ1XVsze6GADm7/anvnrZJczF50994vWe5/Df/9M5VLJ8V/zSU673PLd/zR/OoZLl+/wTnr7sEthHrPf0jEfNPLxJpu9t9p3NAADsF9bb0/ywmeFrklyW5OEbXg0AAGxC6z2n+UnzLgQAADardd0RsKruVFVvqqorq+qKqjqzqu407+IAAGAzWO9ttF+Z5Owkd0hyxyR/28cBAMA+b72heVtr7ZWttWv6z+lJts2xLgAA2DTWG5qvrqonVNUB/ecJSf7vPAsDAIDNYr2h+aeTPDbJ55NcnuSEJC4OBABgv7Der5x7XpKTWmtfTJKqOjTJ72YK0wAAsE9bb0/zPVcCc5K01r6Q5F7zKQkAADaX9fY036SqDlnT03yDbsENALCZ3fGtv7vsEubis8c/83rPc+SO35lDJcv3qe2/er3nWW/w/b0k762qv850++zHJvnt6/1uAACwBa33joCvqqodSR6UpJI8qrV2yVwrAwCATWLdp1j0kCwoAwCw31nvhYAAALDfEpoBAGBAaAYAgIG5heaqekVVXVlVu2bGHVpV51TVpf33IfN6fwAA2Cjz7Gk+Pcnxa8Y9O8m5rbVjkpzbHwMAwKY2t9DcWjsvyRfWjH54kjP68BlJHjGv9wcAgI2y6HOaD2+tXZ4k/fftFvz+AABwvW3aCwGr6pSq2lFVO6666qpllwMAwH5s0aH5iqo6Ikn67yv3NGFr7bTW2vbW2vZt27YtrEAAAFhr0aH57CQn9eGTkvzNgt8fAACut3l+5dxfJnlfkrtW1Weq6meSPD/Jj1TVpUl+pD8GAIBN7cB5vXBr7cQ9PPXgeb0nAADMw6a9EBAAADYLoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBgQGgGAIABoRkAAAaEZgAAGBCaAQBg4MBlvGlVXZbky0muTXJNa237MuoAAID1WEpo7n64tXb1Et8fAADWxekZAAAwsKzQ3JK8vaouqKpTllQDAACsy7JOz7hva+1zVXW7JOdU1cdaa+fNTtDD9ClJcuSRRy6jRgAASLKknubW2uf67yuTvCnJfXYzzWmtte2tte3btm1bdIkAAHCdhYfmqrpVVR28MpzkoUl2LboOAABYr2WcnnF4kjdV1cr7/0Vr7a1LqAMAANZl4aG5tfYvSb530e8LAAA3lK+cAwCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABgQmgEAYEBoBgCAAaEZAAAGhGYAABhYSmiuquOr6uNV9c9V9exl1AAAAOu18NBcVQck+aMkP5rk7klOrKq7L7oOAABYr2X0NN8nyT+31v6ltfYfSf4qycOXUAcAAKzLMkLzHZN8eubxZ/o4AADYlKq1ttg3rHpMkv/aWvvZ/viJSe7TWnvamulOSXJKf3jXJB9faKHf6rAkVy+5hs1CW6zSFqu0xSptsUpbrNIWq7TFKm2xarO0xXe01ratHXngEgr5TJI7zzy+U5LPrZ2otXZaktMWVdRIVe1orW1fdh2bgbZYpS1WaYtV2mKVtlilLVZpi1XaYtVmb4tlnJ7xT0mOqaq7VNVNk/xkkrOXUAcAAKzLwnuaW2vXVNUvJnlbkgOSvKK1dvGi6wAAgPVaxukZaa39XZK/W8Z73wib5lSRTUBbrNIWq7TFKm2xSlus0hartMUqbbFqU7fFwi8EBACArcZttAEAYGC/D81V9fSq+mhVffHG3tK7qt5VVZvqqs+qOqqqds3hdU+tqmfuZvxzq+ohG/1++7qqOr2qTlh2HXtTVV+5gfP96kbXsmw3Zrua1za5VfTl/6ll17FRZo4hr112LZtJVZ1cVXe4gfMeV1U/tNE1zcsyt+nNfuyY1/bR15E3b+Rrrsd+H5qT/HySH2utHdJae/7aJ6tqKed9L1K/tfmGaK09p7X2Dxv1euwT9rnQzI1yVJJ9JjRn9Rjy+NGE+9rxZHDsODnJDQrNSY5Lcr1C877WtruzRZfxW7aPLbocSfbz0FxVf5LkO5OcXVXPqKqX9vGnV9WLquqdSV5QVbeqqldU1T9V1Yer6uF9ultU1V9V1c6qel2SWyxvafbqwKo6o9f511V1y6q6rKqeU1XvSfKYqjq6qt5aVRdU1flVdbckqaqHVdUH+nL/Q1UdvvbFq+rJVfX3vT2u+6+3v8dvVtWHquojM6+5rarO6eP/tKo+WVWHLaoxquqsvpwX95vopKqO7/VcVFXn9nG3rqpX9tp3VtWj+/ivzLzWCVV1eh9+TFXt6q9xXh93QFW9sK87O6vqKX18VdVLq+qSqnpLktstavlvrF77C/uyfqSqHtfHH1FV51XVhf25+1fV85Pcoo/b13ridrddPaf/rXdV1WlVVUlSVffu68X7kvzCkuuei6r6b70tLqqqV9eaHrCZ7eb5Se7f14lnLKfajbHmGPLLfd+ys6reX1X37NOc2teFtyd5Vd8n/O7MfuVpfbp7V9W7+77pbVV1xBIXbaX39GO7WcfXHjuO7cu7s6reVFWH9L/79iSv7X/nW+xp+Wrqibykz/9XVXVUkqcmeUaf9/41HTPO7NvWP1XVffu8a9v2e6rqg32+nVV1zAKb7ICqenlNx5W392V+cq/3ol7/LXvdF878fLWqHlhV96mq99Z0rH1vVd21T3tyVb2hqv42ydv7/ndLHDvWbB//uuZvdVRNWeND/eeH+jzf1IPcl/XkPnx8Xyffk+RRS1ikpLW2X/8kuSzTHWhOTvLSPu70JG9OckB//DtJntCHvy3J/0lyqyT/I9NX5iXJPZNck2T7spdpzfIdlaQluW9//Iokz+zL/ayZ6c5Nckwf/v4k7+jDh2T1gtGfTfJ7ffjU/jq/mOl7tm8203YnzLTt0/rwzyf5sz780iS/0oeP7/UdtsA2ObT/vkWSXUkOz3Rr97usef4FSX5/Zr5D+u+vzIw7IcnpffgjSe64sp7036ck+Z99+GZJdiS5S6YN/pxMX7t4hyRfWmm3zfqzstxJHj1T++FJPpXkiCS/nOTX+jQHJDl4bXvtKz972a4OnZnm1Uke1od3JnlgH35hkl3LXoYNbo/vyXTX1sP640Nn9wVr1p/jkrx52TVv4LJflukY8pIkv9HHPSjJhX341CQXJLlFf/xzSc5McuBMWx2U5L1JtvVxj0s/tixxufa0jl+Wbz52zK7bz13ZZyZ5V/rxcG/Ll+nmZivHj5X95qlJnjnzHn+R5H59+MgkH91D274kyeP78E1Xxi+ora5Jcmx//PokT0jy7TPT/Fb68XBm3MOSnN/b5zYz68RDkpzZh0/OdFO4lePSljp2zGwfa/9Wt0xy8z58TJIdffi4zOwfMuWFk5PcPNNx+pgk1dt44fuRLdtFvgBvaK1d24cfmuQnavUc3ptn2nAfkOQPk6S1trOqdi6+zHX5dGvtH/vwa5I8vQ+/Lpl6VDN9FPaG3jGWTAEvme7Y+LreK3DTJJ+Yed0nZtqYH9Fa+8Ye3vuN/fcFWf3P8H5JHpkkrbW3VtUXb+By3VBPr6pH9uE7Zwq257XWPtFr+kJ/7iGZbr6TPn5U5z8mOb2qXp/V5X5oknvO9LjdNtNG/4Akf9nXsc9V1Ttu5DIt0v2yWvsVVfXuJN+X6cZFr6iqg5Kc1Vq7cJlFLsDutqtPVNWzMh0QDk1ycU2fOnxba+3dfdpXJ/nRhVc7Xw9K8tettauTaRua2ZfsL+6X6R/KtNbeUVXfXlW37c+d3Vr7ah9+SJI/aa1d06f9QlXdI8k9kpzT2+2AJJcvtPrdGx07bptvXrfPSPKG3bzOXbPn5duZqUf6rCRn7aGOhyS5+8w6dZuqOrgPz7bt+5L8WlXdKckbW2uXrntJb7xPzOzzLsgUpO9RVb+VqbPt1pnuT5Ek6b3gL0zyoNbaN6rq9knO6ONbpiC94pyZ49JWPnbM/q0OSvLSqjo2ybVJvmsw790ytfGlSVJVr8l07F4ooXnP/n1muJI8urX28dkJ+ga8Fb6zb22NK49XlvEmSb7UWjt2N/O+JMmLWmtnV9Vxmf5bXLErybGZgvUnvnXWJMnX++9rs7q+Le1o2pfhIUl+sLX2/6rqXUkuyrRT/5bJs/u/7+y4m183srWnVtX3J/nxJBf2nUFl6l142+wLVNWP7eG1t4Ld/v1aa+dV1QMyLf+rq+qFrbVXLba0hdrddvXHmXrXPl1Vp2ZaP/a0Hu1LdreM16SfAljTzvKmiy5qwXa3Xazd165Mt7atKsnFrbUfnEdhN8Lo2LFee1u+H88UBH8iya9X1ffsZpqbZNpnf3V2ZD8GX1dLa+0vquoD/TXfVlU/21pbVKj8+szwtZk+yTw9U6fSRf0Ug+OSpKpulamn9Mmttc/1eZ6X5J2ttUf2U1TeNfN6a9t7q+5PZpfjGUmuSPK9mf6+X+vjr9tvdDefGV76cu/X5zRfD29L8rS+409V3auPPy/J4/u4e2Q6RWMzOrKqVnZWJyZ5z+yTrbV/y9RD9pjkunNWv7c/fdskn+3DJ6153Q8neUqm85WuzwUf70ny2P5eD810Csii3DbJF3tgvluSH8jUq/7AqrpLr+nQPu3bM51+kj5+pc4rquq7q+om6T3m/fmjW2sfaK09J8nVmXqx35bk53rva6rqu/oO87wkP1nT+Y1HJPnhOS7zRjsvyeN67dsyHfA+WFXfkeTK1trLk/x5kv/Sp//GyvLvY/a0XV3dP705IUlaa19K8q9Vdb/+/PCCsS3o3CSPrapvT67bhi5Lcu/+/MOz2nP25SQHr32BfcDs8eC4JFf3fetab0/y1OoXQ/W2+niSbSvrU1UdtIfwuGijY8e/JvliVd2/j3pikpVe59m/826Xr+9D79xae2eSZ2W1R3btOrJ2X7y7Dp5U1Xcm+ZfW2h9mOm1w2cfkg5Nc3vd/s9v9K5O8srV2/sy42WPtyXt5za187Jh12ySXt9b+M9N6s3JR6Sczfapws/5JxoP7+I8luUtVHd0fn7jQajuheX2el2mHv7Omr5V5Xh//siS37qdlPCvJB5dU38hHk5zU6zw0U91rPT7Jz1TVRUkuznSQS6ae5TdU1fmZguA3aa29J9N5bm+p9V/M95tJHlpVH8r0MfXlmXaSi/DWTBdw7cz0d3x/kqsyfczzxr78r+vT/laSQ6pf3JfVndOzM53z/o5880eoL6zp4p5dmXZsFyX5sySXJPlQH/+nmXrc35Tk0kznQb8sqweareBNmT5SvShTGzyrtfb5TL0oF1bVhzN9TP0HffrTMm07+9qFgLvbrl6e6W96VqbTVVY8Kckf1XQh4FfXvtBW11q7OMlvJ3l331ZelKktHlhVH8x0ncRKL9POJNfUdHHUlr4QcI1Tk2zv68Pz862dDCv+LNN1ADt7W/1Ua+0/Mv2T9YI+7sJcz2+PmJP1HDtOyrTv25npk8fn9vGnJ/mTqrowUyDa3fIdkOQ1VfWRTJ0wL+7/ZP5tkkdWvxAw02kh22u6uO+STBcK7s7jkuzq73m3JMv+pOvXk3wg0znIH0uS3rlwQpKfrtWLAbcn+d9J/ldV/WNWA+TubOVjx6w/zrRuvT/TqRn/niSttU9n6oXfmeS1mdaLtNa+luk4/ZaaLgT85DKKdkdAFq6qbpbk2tbaNb3n4WV7ODUEgCXopwi8ubV2jyWXApuGc5pZhiOTvL5/NPcfSZ685HoAAPZKTzMAAAw4pxkAAAaEZgAAGBCaAQBgQGgG2I9V1XFV9eZl1wGw2QnNAPuRqtrbd8ACsAdCM8AWUVXPqqqn9+EXV9U7+vCDq+o1VXXiyg12quoFM/N9paqe228x/INVdXxVfazfJOBRy1kagK1FaAbYOs5LsnLL4u2Z7kh6UJL7ZbpL2AuSPCjTndm+r6oe0ae9VZJdrbXvT7Ij0936HtZf6/aLKx9g6xKaAbaOC5Lcu6oOTvL1JO/LFJ7vn+RLSd7VWruqtXZNplvQPqDPd22SM/vw3ZJ8orV2aZu+qP81i1wAgK1KaAbYIlpr30hyWZInJXlvkvOT/HCSo5N8ai+zfq21du3sS82rRoB9ldAMsLWcl+SZ/ff5SZ6a5MIk70/ywKo6rF/sd2KSd+9m/o8luUtVHd0fnzj/kgG2PqEZYGs5P8kRSd7XWrsiydeSnN9auzzJryR5Z5KLknyotfY3a2durX0tySlJ3tIvBPzkwioH2MJqOqUNAADYEz3NAAAwIDQDAMCA0AwAAANCMwAADAjNAAAwIDQDAMCA0AwAAANCMwAADPx/jIm2Q5Fo1tAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.barplot(x='word', y='count',data=n, palette='winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation\n",
    "\n",
    "The features that I create include TF-IDF scores and Sentiment for each tweet. The TF-IDF scores are created further down when I perform my semantic analyses. However, I generate the sentiment here. I generate two columns containing the positive percentage of words in the tweet and the negative percentage of words in the tweet. \n",
    "\n",
    "To generate positive and negative sentiment for each tweet I tokenize the words in each tweet, I then lemmatize the words before a sentiment is created. Using the lemmatized words the percentage of positive words in the tweet are calculated and the percentage of negative words in the tweet are calculated. These two proportions are added into the dataset as 'sent_pos' as 'sent_neg'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Sentiment for each Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_pct(x):\n",
    "    try:\n",
    "        pos = x.positive\n",
    "    except:\n",
    "        pos = 0\n",
    "    try:\n",
    "        neg = x.negative\n",
    "    except:\n",
    "        neg = 0\n",
    "    try:\n",
    "        neu = x.neutral\n",
    "    except:\n",
    "        neu = 0\n",
    "    try:\n",
    "        pct_pos = pos / (pos + neg + neu)\n",
    "    except:\n",
    "        pct_pos = 0\n",
    "    return(pct_pos)\n",
    "\n",
    "def neg_pct(x):\n",
    "    try:\n",
    "        pos = x.positive\n",
    "    except:\n",
    "        pos = 0\n",
    "    try:\n",
    "        neg = x.negative\n",
    "    except:\n",
    "        neg = 0\n",
    "    try:\n",
    "        neu = x.neutral\n",
    "    except:\n",
    "        neu = 0\n",
    "    try:\n",
    "        pct_neg = neg / (pos + neg + neu)\n",
    "    except:\n",
    "        pct_neg = 0\n",
    "    return(pct_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = WordNetLemmatizer()\n",
    "def process_text(x):\n",
    "    x = x.lower()\n",
    "    tokens = wordpunct_tokenize(x)\n",
    "    tokens = [tok for tok in tokens if tok.isalnum()]\n",
    "    tokens = [wn.lemmatize(tok) for tok in tokens]\n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pos = []\n",
    "for tweet in dataFinal['tweet']:\n",
    "    c = Counter(process_text(tweet))\n",
    "    tmp = pd.DataFrame(c.items(), columns=['word','count'])\n",
    "    tmp = tmp.merge(sentiments, how='inner')\n",
    "    x = tmp['sentiment'].value_counts()\n",
    "    sent_pos.append(pos_pct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_neg = []\n",
    "for tweet in dataFinal['tweet']:\n",
    "    c = Counter(process_text(tweet))\n",
    "    tmp = pd.DataFrame(c.items(), columns=['word','count'])\n",
    "    tmp = tmp.merge(sentiments, how='inner')\n",
    "    x = tmp['sentiment'].value_counts()\n",
    "    sent_neg.append(neg_pct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFinal['sent_pos'] = sent_pos\n",
    "dataFinal['sent_neg'] = sent_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>tweet</th>\n",
       "      <th>delta_bin</th>\n",
       "      <th>sent_pos</th>\n",
       "      <th>sent_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>AAP</td>\n",
       "      <td>highlights annual mobil twelve hours sebring p...</td>\n",
       "      <td>down</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>ANTM</td>\n",
       "      <td>today released legendary anthem empowerment no...</td>\n",
       "      <td>down</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.014085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>BLK</td>\n",
       "      <td>years ago michael jordan ridiculous line vs pt...</td>\n",
       "      <td>down</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>CARR</td>\n",
       "      <td>south korean korean air says buy smaller troub...</td>\n",
       "      <td>up</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>CE</td>\n",
       "      <td>great post awhile ago rise nazi hippies worth ...</td>\n",
       "      <td>up</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker                                              tweet  \\\n",
       "0  2020-11-16    AAP  highlights annual mobil twelve hours sebring p...   \n",
       "1  2020-11-16   ANTM  today released legendary anthem empowerment no...   \n",
       "2  2020-11-16    BLK  years ago michael jordan ridiculous line vs pt...   \n",
       "3  2020-11-16   CARR  south korean korean air says buy smaller troub...   \n",
       "4  2020-11-16     CE  great post awhile ago rise nazi hippies worth ...   \n",
       "\n",
       "  delta_bin  sent_pos  sent_neg  \n",
       "0      down  0.000000  0.000000  \n",
       "1      down  0.014085  0.014085  \n",
       "2      down  0.000000  0.074074  \n",
       "3        up  0.000000  0.125000  \n",
       "4        up  0.041667  0.041667  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFinal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods & Results\n",
    "\n",
    "I selected semantic and sentiment approaches because they are the two most common approaches to natural languge processing that have been discussed on literature regarding the topic. \n",
    "\n",
    "### Semantic Model Approach\n",
    "\n",
    "A semantic model approach takes into account the frequency of the words used as a proportion of the words in a tweet and in the dataset. A popular way of doing this is using TF-IDF scores. TF-IDF stands for \"total frequency-inverse document frequency\". Each word in the dataset is assigned a value, calculated based on how often it is used.\n",
    "\n",
    "First I break the data into testing and training datasets. I use a 70/30 training test split stratified on the categorical change in the price of that stock for that day. I generate TF-IDF scores using the TfidfVectorizer function in the sklearn package in Python. \n",
    "\n",
    "Once the TF-IDF scores have been calculated I try classification using a Multinomial Naive Bayes classifier and a Random Forest Classifier. The Multinomial Naive Bayes is a good method for text classificaiton and results in an accuracy of 0.53 and an F1 Score of 0.61. The reason that I selected the Multinomial Naive Bayes estimator is because it doesn't require much training data and is relatively quick compared to other classifiers. It could be used to make almost real time stock market predictions. Unfortunately, one of the main limitations of the Multinomial Naive Bayes classifier is it makes the simplifying assumption that there is no relationship between variables. The results from the Multinomial Naive Bayes estimator are very similar to the results obtained using the Random Forest classifier which produces an accuracy of 0.55 and an F1 score of 0.65. The reason I chose to use a Random Forest is because it has historically handled classification problems very well. This is because it relies on multiple iterations and decision trees to get the most accurate prediction. The Random Forest model does have weaknesses, including that they are not very interpretable and tend to overfit. However, based on the confusion matrix it seems there is no evidence of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataFinal, \n",
    "                               test_size=.3,\n",
    "                               stratify=dataFinal.delta_bin, \n",
    "                               random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = (train['delta_bin'] == 'up').astype(int)\n",
    "y_test = (test['delta_bin'] == 'up').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_df = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit(train['tweet'])\n",
    "X_train = tfidf.transform(train['tweet'])\n",
    "X_test = tfidf.transform(test['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28, 58],\n",
       "       [27, 68]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "yhat_test = nb.predict(X_test)\n",
    "confusion_matrix(y_test, yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5303867403314917"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6153846153846154"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5396825396825397"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, yhat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23, 63],\n",
       "       [19, 76]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(100)\n",
    "rf.fit(X_train, y_train)\n",
    "yhat = rf.predict(X_test)\n",
    "confusion_matrix(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5469613259668509"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6495726495726496"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5467625899280576"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Approach\n",
    "\n",
    "Using the sentiments created in the Feature Creation section, I perform two different analyses using a Logistic Regression approach and a Random Forest Classifier. \n",
    "\n",
    "Again, I break my data into a 70/30 train test split stratified on binary increases or decreases in stock price changes for that company on a given day. The Logistic Regression approach was unsuccessful in its classification because it only predicted increases in stock market price. This resulted in an accuracy of 0.52 and an F1 Score of 0.69 percent. The reason I chose to use a logistic regression model is because it is one of the most basic models for classification and I thought that it might perform well because there aren't very many explanatory variables to deal with. However, Logistic Regression requires a large amount of data which I do not have and that is one weakness of the model. The Random Forest predicted an accuracy of 0.49, just at the accuracy of chance classification, and an F1 Score of 0.59. I chose to use the Random Forest because it performed well in the semantic analysis and because it generally performs well. The weaknesses of the Random Forest are outlined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataFinal, \n",
    "                               test_size=.3,\n",
    "                               stratify=dataFinal.delta_bin, \n",
    "                               random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['sent_pos', 'sent_neg']]\n",
    "X_test = test[['sent_pos', 'sent_neg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = (train['delta_bin'] == 'up').astype(int)\n",
    "y_test = (test['delta_bin'] == 'up').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Using Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 86],\n",
       "       [ 0, 95]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LogisticRegression(solver='liblinear', random_state=123)\n",
    "lm.fit(X_train, y_train)\n",
    "yhat = lm.predict(X_test)\n",
    "confusion_matrix(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5248618784530387"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6884057971014492"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5248618784530387"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Using Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 67],\n",
       "       [28, 67]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(100)\n",
    "rf.fit(X_train, y_train)\n",
    "yhat = rf.predict(X_test)\n",
    "confusion_matrix(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47513812154696133"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5851528384279476"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination and Results\n",
    "\n",
    "The steps that I took to improve my predictions can be seen in three different aspects of this report. First, cleaning the text was an important step. I removed unwanted and insignificant words as well as lemmatized the words so that the TF-IDF and sentiment metrics would give more accurate insight into the data. Then I tried a semantic approach and a sentiment approach. Within each of these approaches, I tried two different machine learning models. In addition, I tried an ensemble method (not included in this write up) that did not out-perform either method. The Random Forest outperformed my first attempt in both semantic and sentiment approaches. While none of the models performed well, there is promise that natural language processing of tweets can predict the change in the stock price of a company. \n",
    "\n",
    "The model performance metrics that I chose to use were Accuracy, F1 Score, and Precision. \n",
    "\n",
    "* Accuracy - The number of correct predictions over the number of total predictions.\n",
    "* F1 Score - The number of true positives divided by the number of true positives times one-half false positives plus false negatives.\n",
    "* Precision - The number of correct positives over the number of total positives. \n",
    "\n",
    "I chose these methods because they are standard across the machine learning industry and give a good view of the strengths and weaknesses of the model.\n",
    "\n",
    "The methods and models that I tried do not predict the closing price of specific stocks well. However, as a general trend the semantic methods outperformed the sentiment methods. Of the two semantic methods the Random Forest model performed the best. The semantic models both performed slightly better than chance and indicate that there could be a relationship between tweets and stock performance. The sentiment models on the other hand did not perform well. In fact, the Random Forest did not perform any better than chance based off its accuracy metric. The Logistic Regression method did not perform well, while it's F1 Score is high, the confusion matrix indicates that the model always predicted an increase in stock price. This is not a viable way to perform an analysis and is not good for long term prediction. \n",
    "\n",
    "#### Using semantic analysis, tweets can be used to predict changes in stock price. However, further research with more data should be considered to draw a more conclusive result.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Answering the question of whether tweets can predict fluctuations in the stock market is a difficult task. It involves gathering data from the Twitter server and scraping stock data from the web. Once the data has been cleaned and collected, exploratory data analysis reveiled trends in the data such as prominent names, current event topics, and company names. I also was able to get a grasp of what positive and negative words were commonly used.\n",
    "\n",
    "At the conclusion of the EDA I created sentiment features for the positive and negative sentiment contained within a tweet. Using this method and the TF-IDF features I ran semantic and sentiment analyses to classify increases or decreases in stock price. Neither of the methods produced results with a high degree of prediction accuracy. However, there is promise in the results provided by the semantic models. The semantic models slightly outperformed the accuracy of chance which leads me to conclude that given additional research and study relationships could be amplified to produce greater prediction accuracy. \n",
    "\n",
    "One weakness of my analysis shows in the results provided by the Logistic Regression analysis. The Logistic Regression predicted only increases. This is likely due to the relatively small size of the dataset. Given the limited time to pull tweets (3 weeks) the data was sparse. Had I had more time, I would have pulled more tweets from subsequent weeks to increase the amount of data and hopefully the accuracy of the model. I think that one source of bias that I would fix given more time would be improving the search words used to find tweets. I would expand the search words to include names of company executives as well as other ways of referring to a company (ex. Apple instead of Apple Inc.). \n",
    "\n",
    "There are lots of fields of research that could be explored on this topic. However, one of particular interest to me is adding general public mood to the analysis. In the literature review file that I have attached I discuss how sentiment models perform well when predicting the aggregate rise and fall of the stock market. This general mood could be added in as a feature to this model in addition TF-IDF scores. There are many reasons why someone invests or sells and knowing the general mood of the public could add to the predictability of these models. In addition, current events have also been proven a good indicator of aggregate stock market changes and could be an interesting factor to incorporate for predicting individual stocks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
